{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "'''\n",
    "Proyecto Final Procesamiento inteligente de Textos\n",
    "Integrantes:\n",
    "Barcenas Martinez Edgar Daniel\n",
    "Martinez Troncoso Julio Cesar\n",
    "Silva Sandoval Cecilia\n",
    "'''\n",
    "\n",
    "'''\n",
    "Se obtuvieron datos de \n",
    "https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "El dataset tiene 50,000 críticas de películas de estas la mitad son para \n",
    "entrenamiento el la otra para prueba. Cada parte tiene 12,500 criticas positivas\n",
    "y 12,500 criticas negativas.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "Metodo de limpieza de las review\n",
    "Quitamos signos de puntuacion.\n",
    "Etiquetas HTML y conversion del texto a minuscula\n",
    "'''\n",
    "def preprocesamiento_reviews(reviews):\n",
    "    remplazar_sin_espacio = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "    remplazar_con_espacio = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    sin_espacio = \"\"\n",
    "    espacio = \" \"\n",
    "    reviews = [remplazar_sin_espacio.sub(sin_espacio, line.lower()) for line in reviews]\n",
    "    reviews = [remplazar_con_espacio.sub(espacio, line) for line in reviews]\n",
    "    return reviews\n",
    "\n",
    "'''\n",
    "Eliminamos palabras funcionales \n",
    "para mejorar el rendimiento de un modelo\n",
    "'''\n",
    "def eliminar_palabras_funcionales(corpus):\n",
    "    palabras_funcionales = ['in', 'of', 'at', 'a', 'the']#stopwords.words('english')\n",
    "    sin_palabras_funcionales = []\n",
    "    for review in corpus:\n",
    "        sin_palabras_funcionales.append(' '.join([palabra for palabra in review.split()\n",
    "            if palabra not in palabras_funcionales]))\n",
    "    return sin_palabras_funcionales\n",
    "\n",
    "\n",
    "'''\n",
    "Stemming\n",
    "Normalización\n",
    "'''\n",
    "def get_stemmed_text(corpus):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(palabra) for palabra in review.split()]) for review in corpus]\n",
    "\n",
    "'''\n",
    "Lemmatization\n",
    "Transformar la palabra en su raíz verdadera.\n",
    "'''\n",
    "def get_lemmatized_text(corpus):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(palabra) for palabra in review.split()]) for review in corpus]\n",
    "\n",
    "def preprocesamiento_review(review):\n",
    "    review = eliminar_palabras_funcionales(review)\n",
    "    review = get_stemmed_text(review)\n",
    "    review = get_lemmatized_text(review)\n",
    "    return review\n",
    "\n",
    "'''Lectura de datos'''\n",
    "def leer_review_entrenamiento():\n",
    "    reviews_train = []\n",
    "    for line in open('movie_data/full_train.txt', 'r'):\n",
    "        reviews_train.append(line.strip())\n",
    "    return reviews_train\n",
    "\n",
    "def leer_review_prueba():\n",
    "    reviews_test = []\n",
    "    for line in open('movie_data/full_test.txt', 'r'):\n",
    "        reviews_test.append(line.strip())\n",
    "    return reviews_test\n",
    "\n",
    "def exactitud(X_train, X_val, y_train, y_val):\n",
    "    for c in [0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "        svm = LinearSVC(C=c)\n",
    "        svm.fit(X_train, y_train)\n",
    "        print (\"Exactitud for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "def exactitudFinal(final,target,X,X_test):\n",
    "    final.fit(X, target)\n",
    "    print (\"Final Exactitud: %s\" \n",
    "       % accuracy_score(target, final.predict(X_test)))\n",
    "\n",
    "def prediccion(final,reviews_new,ngram_vectorizer):\n",
    "    reviews_new_counts = ngram_vectorizer.transform(reviews_new)\n",
    "    resultado = final.predict(reviews_new_counts)\n",
    "    return resultado\n",
    "\n",
    "def svmModificado(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "    ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "    ngram_vectorizer.fit(reviews_train_clean)\n",
    "    X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "    X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75)\n",
    "    c=0.01\n",
    "    final = LinearSVC(C=c)\n",
    "    exactitudFinal(final,target,X,X_test)\n",
    "    return final,ngram_vectorizer\n",
    "\n",
    "'''\n",
    "Se incluyen pares de palabras para tener mejor precisión\n",
    "Este modelo probabilístico permite hacer una predicción estadística del próximo elemento.\n",
    "'''\n",
    "def modeloNgrams(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "    ngram_vectorizer.fit(reviews_train_clean)\n",
    "    X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "    X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, target, train_size = 0.75)\n",
    "   \n",
    "    final_ngram = LogisticRegression(C=0.5)\n",
    "    final_ngram.fit(X, target)\n",
    "    exactitudFinal(final_ngram,target,X,X_test)\n",
    "    return final_ngram,ngram_vectorizer\n",
    "'''\n",
    "Se utiliza la tecnica de recuento de palabras\n",
    "para verificar si una palabra aparece mas de una vez y \n",
    "ayudar a determinar si esta es positiva o negativa\n",
    "'''\n",
    "def word_Counts(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    wc_vectorizer = CountVectorizer(binary=False)\n",
    "    wc_vectorizer.fit(reviews_train_clean)\n",
    "    X = wc_vectorizer.transform(reviews_train_clean)\n",
    "    X_test = wc_vectorizer.transform(reviews_test_clean)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, target, train_size = 0.75,)\n",
    "    \n",
    "    final_wc = LogisticRegression(C=0.05)\n",
    "    final_wc.fit(X, target)\n",
    "    exactitudFinal(final_wc,target,X,X_test)\n",
    "    return final_wc,wc_vectorizer\n",
    "\n",
    "'''\n",
    "Término frecuencia de documento inversa de frecuencia:\n",
    "Este representa la cantidad de veces que aparece una palabra especifica en la review.\n",
    "'''\n",
    "def TFIDF(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_vectorizer.fit(reviews_train_clean)\n",
    "    X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "    X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, target, train_size = 0.75)\n",
    "    \n",
    "    final_tfidf = LogisticRegression(C=1)\n",
    "    final_tfidf.fit(X, target)\n",
    "    exactitudFinal(final_tfidf,target,X,X_test)\n",
    "    # Final Accuracy: 0.882\n",
    "    return final_tfidf,tfidf_vectorizer\n",
    "\n",
    "''' \n",
    "SVM + Ngrams nos da la mejor precisió del 90%\n",
    "SVM clasificadol lineal con ngram_range=(1, 3)\n",
    "'''\n",
    "def svmModificado(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "    ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "    ngram_vectorizer.fit(reviews_train_clean)\n",
    "    X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "    X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75)\n",
    "    c=0.01\n",
    "    final = LinearSVC(C=c)\n",
    "    exactitudFinal(final,target,X,X_test)\n",
    "    return final,ngram_vectorizer\n",
    "\n",
    "'''SVM clasificadol lineal con ngram_range=(1, 2)'''\n",
    "def svm(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "    ngram_vectorizer.fit(reviews_train_clean)\n",
    "    X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "    X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, target, train_size = 0.75)\n",
    "    final_svm_ngram = LinearSVC(C=0.01)\n",
    "    final_svm_ngram.fit(X, target)\n",
    "    exactitudFinal(final_svm_ngram,target,X,X_test)\n",
    "    return final_svm_ngram, ngram_vectorizer\n",
    "\n",
    "'''\n",
    "Naive_Bayes\n",
    "Clasificamos en función de las probabilidades de las palabras.\n",
    "'''\n",
    "def Naive_Bayes(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "    movie_vec = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "    movie_vec.fit(reviews_train_clean)\n",
    "    X = movie_vec.transform(reviews_train_clean)\n",
    "    X_test = movie_vec.transform(reviews_test_clean)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75,)\n",
    "    final_movie_vec = MultinomialNB()\n",
    "    final_movie_vec.fit(X, target)\n",
    "    exactitudFinal(final_movie_vec,target,X,X_test)\n",
    "    return final_movie_vec,movie_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Exactitud: 0.90064\n",
      "Modelo SVM con Ngram (1,3)\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "''' Main '''\n",
    "'''Leemos y limpiamos los datos de entarda'''\n",
    "reviews_train = leer_review_entrenamiento()\n",
    "reviews_test = leer_review_prueba()\n",
    "reviews_train_clean = preprocesamiento_reviews(reviews_train)\n",
    "reviews_test_clean = preprocesamiento_reviews(reviews_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Entreamos el modelo svm con g-grams(1,3)\n",
    "modelo,vector = svmModificado(reviews_train_clean,reviews_test_clean)\n",
    "review = \"A breezily unpredictable blend of teen romance and superhero action, Spider-Man: Far from Home stylishly sets the stage for the next era of the MCU.\"\n",
    "reviews_new = [review]\n",
    "resultado = prediccion(modelo,reviews_new,vector)\n",
    "print(\"Modelo SVM con Ngram (1,3)\")\n",
    "print(resultado)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "justice = \"bad , I've just seen one of the boldest mainstream American movies in ages.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "reviews_new = [justice]\n",
    "resultado = prediccion(modelo,reviews_new,vector)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entreamos el modelo Naive_Bayes\n",
    "modelo,vector = Naive_Bayes(reviews_train_clean,reviews_test_clean)\n",
    "review = \"A breezily unpredictable blend of teen romance and superhero action, Spider-Man: Far from Home stylishly sets the stage for the next era of the MCU.\"\n",
    "reviews_new = [review]\n",
    "resultado = prediccion(modelo,reviews_new,vector)\n",
    "print(\"Modelo Naive_Bayes: \")\n",
    "print(resultado)\n",
    "\n",
    "#Entreamos el modelo svm\n",
    "modelo,vector = svm(reviews_train_clean,reviews_test_clean)\n",
    "review = \"A breezily unpredictable blend of teen romance and superhero action, Spider-Man: Far from Home stylishly sets the stage for the next era of the MCU.\"\n",
    "reviews_new = [review]\n",
    "resultado = prediccion(modelo,reviews_new,vector)\n",
    "print(\"Modelo SVM: \")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entreamos el modelo TFIDF\n",
    "modelo,vector = TFIDF(reviews_train_clean,reviews_test_clean)\n",
    "review = \"A breezily unpredictable blend of teen romance and superhero action, Spider-Man: Far from Home stylishly sets the stage for the next era of the MCU.\"\n",
    "reviews_new = [review]\n",
    "resultado = prediccion(modelo,reviews_new,vector)\n",
    "print(\"Modelo TFIDF\")\n",
    "print(resultado)\n",
    "\n",
    "#Entreamos el modelo word_Counts\n",
    "modelo,vector = word_Counts(reviews_train_clean,reviews_test_clean)\n",
    "review = \"A breezily unpredictable blend of teen romance and superhero action, Spider-Man: Far from Home stylishly sets the stage for the next era of the MCU.\"\n",
    "reviews_new = [review]\n",
    "resultado = prediccion(modelo,reviews_new,vector)\n",
    "print(\"Modelo Word Counts\")\n",
    "print(resultado)\n",
    "\n",
    "#Entreamos el modelo modeloNgrams\n",
    "modelo,vector = modeloNgrams(reviews_train_clean,reviews_test_clean)\n",
    "review = \"A breezily unpredictable blend of teen romance and superhero action, Spider-Man: Far from Home stylishly sets the stage for the next era of the MCU.\"\n",
    "reviews_new = [review]\n",
    "resultado = prediccion(modelo,reviews_new,vector)\n",
    "print(\"N-grams\")\n",
    "print(resultado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
